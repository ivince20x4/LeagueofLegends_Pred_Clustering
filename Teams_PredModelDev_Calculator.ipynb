{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Teams_PredModelDev_Cal_Finalfeatures.ipynb","provenance":[{"file_id":"1ppNhm7s2sZ9-3HOAvwGC-WPFrCU-Maiz","timestamp":1583421751267}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TeFKo-ADXUAN"},"source":["# Teams_ModelDev_Calculator\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"L0AVr53T2aU2"},"source":["## Import libraries"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vE9Qz9uj0xbC","colab":{}},"source":["# just run this chunk of code and follow the prompt that it spits out\n","# install PyDrive\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","# authenticate and create the PyDrive client\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"P4mqr0KGX4Ae","colab":{}},"source":["# import packages\n","import warnings\n","\n","# EDA\n","import itertools\n","from statistics import mean \n","import scipy\n","import scipy.stats as st\n","import statsmodels.api as sm\n","import time\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import matplotlib.gridspec as gridspec\n","\n","# preprocessing\n","import numpy as np\n","from numpy import unique\n","import pandas as pd\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import StandardScaler\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import GridSearchCV\n","\n","# algorithms\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","# ensemble methods\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from mlxtend.classifier import EnsembleVoteClassifier\n","from mlxtend.classifier import StackingCVClassifier\n","\n","# print model results\n","from sklearn.datasets import make_classification\n","from sklearn.metrics import classification_report, \\\n","confusion_matrix, accuracy_score, precision_score, recall_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import roc_curve\n","\n","# save models for production\n","import pickle\n","\n","# to ignore warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wuqyHa5s0n6r"},"source":["## Read cleaned files"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"q85LBW5R0n6y","outputId":"7c78bc73-af34-46fb-87db-6dd3ca81ec84","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Teams version 3 data\n","link = 'https://drive.google.com/open?id=1_PktzNW5-6cbf5nHBXvSCs4Y94UA6ck7'\n","fluff, id = link.split('=')\n","downloaded = drive.CreateFile({'id':id}) \n","downloaded.GetContentFile('Teams_v3.csv')  \n","Teams_df = pd.read_csv('Teams_v3.csv')\n","\n","print(Teams_df.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(10886, 50)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DX8S9ZylSOH_","colab_type":"text"},"source":["## Filter data with features selected from EDA scripts"]},{"cell_type":"code","metadata":{"id":"GEHWZvUvSOIB","colab_type":"code","outputId":"47abbbd9-0949-4d8f-d733-af619532e949","colab":{}},"source":["features_selected = ['d', 'kpm','ft','teamtowerkills','fbarontime','elementals',\n","'wcpm','minionkills','xpat10','gdiffat15','result'] \n","Teams_df = Teams_df[features_selected]\n","Teams_df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>d</th>\n","      <th>kpm</th>\n","      <th>ft</th>\n","      <th>teamtowerkills</th>\n","      <th>fbarontime</th>\n","      <th>elementals</th>\n","      <th>wcpm</th>\n","      <th>minionkills</th>\n","      <th>xpat10</th>\n","      <th>gdiffat15</th>\n","      <th>result</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>18.0</td>\n","      <td>0.118188</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>21.536467</td>\n","      <td>0.0</td>\n","      <td>0.709127</td>\n","      <td>691.0</td>\n","      <td>18625.0</td>\n","      <td>-3854.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3.0</td>\n","      <td>0.709127</td>\n","      <td>0.0</td>\n","      <td>10.0</td>\n","      <td>21.536467</td>\n","      <td>2.0</td>\n","      <td>1.063690</td>\n","      <td>693.0</td>\n","      <td>18807.0</td>\n","      <td>3854.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>28.0</td>\n","      <td>0.554734</td>\n","      <td>0.0</td>\n","      <td>10.0</td>\n","      <td>23.230017</td>\n","      <td>0.0</td>\n","      <td>0.798817</td>\n","      <td>1117.0</td>\n","      <td>17739.0</td>\n","      <td>-1283.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>25.0</td>\n","      <td>0.621302</td>\n","      <td>1.0</td>\n","      <td>6.0</td>\n","      <td>23.230017</td>\n","      <td>3.0</td>\n","      <td>1.153846</td>\n","      <td>1080.0</td>\n","      <td>18289.0</td>\n","      <td>1283.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.0</td>\n","      <td>0.784314</td>\n","      <td>1.0</td>\n","      <td>10.0</td>\n","      <td>20.965183</td>\n","      <td>2.0</td>\n","      <td>0.610022</td>\n","      <td>665.0</td>\n","      <td>19356.0</td>\n","      <td>4830.0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      d       kpm   ft  teamtowerkills  fbarontime  elementals      wcpm  \\\n","0  18.0  0.118188  1.0             4.0   21.536467         0.0  0.709127   \n","1   3.0  0.709127  0.0            10.0   21.536467         2.0  1.063690   \n","2  28.0  0.554734  0.0            10.0   23.230017         0.0  0.798817   \n","3  25.0  0.621302  1.0             6.0   23.230017         3.0  1.153846   \n","4   2.0  0.784314  1.0            10.0   20.965183         2.0  0.610022   \n","\n","   minionkills   xpat10  gdiffat15  result  \n","0        691.0  18625.0    -3854.0       0  \n","1        693.0  18807.0     3854.0       1  \n","2       1117.0  17739.0    -1283.0       1  \n","3       1080.0  18289.0     1283.0       0  \n","4        665.0  19356.0     4830.0       1  "]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nMsi2QxS1dxd"},"source":["## Split data into training and test set"]},{"cell_type":"markdown","metadata":{"id":"7qqaFHUnSOIH","colab_type":"text"},"source":["Split data into 70% training set and 30% test set with stratifying on response variable to ensure balance between winning and losing matches in both training and test"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kVX1ubx50n7z","outputId":"6d785a09-5c97-48c4-86d2-ef6c5cf90ad2","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Train and Test Split of Team Data into 70% and 30%\n","# random state 23\n","\n","X = Teams_df.drop(['result'], inplace=False, axis=1)\n","y = Teams_df.result\n","# split into train/test sets with same class ratio\n","train_teamX, test_teamX, train_teamY, test_teamY = train_test_split(X, y, \n","                                                                    test_size=0.3, \n","                                                                    random_state=23, stratify=y)\n","# summarize\n","train_0, train_1 = len(train_teamY[train_teamY==0]), len(train_teamY[train_teamY==1])\n","test_0, test_1 = len(test_teamY[test_teamY==0]), len(test_teamY[test_teamY==1])\n","print('Train: 0=%d, 1=%d, Test: 0=%d, 1=%d' % (train_0, train_1, test_0, test_1))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train: 0=3810, 1=3810, Test: 0=1633, 1=1633\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GSV30zws0n71"},"source":["## Standardization of predictor variables for models"]},{"cell_type":"markdown","metadata":{"id":"z_OPoU4KSOIO","colab_type":"text"},"source":["Standardizing of the predictors using mean and variance of predictors in train"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ioWnJlXB0n71","colab":{}},"source":["scaler = StandardScaler()\n","scaler.fit(train_teamX)\n","scaledtrain_teamX = scaler.transform(train_teamX)\n","scaledtest_teamX = scaler.transform(test_teamX)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"I_Y8HFu01oDq"},"source":["## Model development"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Y_mL1NkHIumK"},"source":["As our target variable is binary and our goal is to create the best predictor model, we will train data on following models:\n","- Logistic regression (baseline)\n","- Naive Bayes classifier\n","- KNN classifier\n","- Random Forest classifier\n","- Bagging ensemble\n","- Boosting (Adaboost on decision tree)\n","- Ensemble voting classifier\n","- Stacked classification (basic and with MLP)"]},{"cell_type":"markdown","metadata":{"id":"uUtF3EzKSOIX","colab_type":"text"},"source":["**Goal**:\n","\n","Improve accuracy of identifying real win and losing as well as reducing false positives for win are important for us because we do not want the team to be highly optimistic of their chances of winning a match but continue to strive hard to improve themselves."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XNltjHaS0n73"},"source":["### Implement logistic regression"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zbmPw-3PIYLf"},"source":["as baseline model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qjnjLZxc0n74","outputId":"7b297a85-c35a-4d9a-c9df-cbc9e8c47ae2","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["logreg = LogisticRegression(C= 10**3, random_state=23)\n","logreg.fit(scaledtrain_teamX, train_teamY)\n","y_pred = logreg.predict(scaledtest_teamX)\n","\n","logreg_train_accuracy  = logreg.score(scaledtrain_teamX, train_teamY)\n","print('Accuracy on training set: {:.4f}'.format(logreg_train_accuracy))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy on training set: 0.9787\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Fe0ZyGsuSOIg","colab_type":"text"},"source":["Model evaluation results on test"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iYN-uB7K0n76","outputId":"bc542702-69b4-41ee-c044-3edc7ab0f025","colab":{"base_uri":"https://localhost:8080/","height":290}},"source":["logreg_result = pd.DataFrame(confusion_matrix(test_teamY, y_pred),\n","                             index=logreg.classes_, \n","                             columns=logreg.classes_)\n","print(\"Confusion Matrix:\")\n","print(logreg_result)\n","logreg_result1 = classification_report(test_teamY, y_pred)\n","print(\"Classification Report:\",)\n","print (logreg_result1)\n","logreg_result2 = accuracy_score(test_teamY,y_pred)\n","print(\"Accuracy at holdout:\",logreg_result2)\n","logreg_precision = precision_score(test_teamY, y_pred)\n","print(\"Precision at holdout:\", logreg_precision)\n","logreg_recall = recall_score(test_teamY, y_pred)\n","print(\"Recall at holdout:\", logreg_recall)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Confusion Matrix:\n","      0     1\n","0  1590    43\n","1    40  1593\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.97      0.97      1633\n","           1       0.97      0.98      0.97      1633\n","\n","    accuracy                           0.97      3266\n","   macro avg       0.97      0.97      0.97      3266\n","weighted avg       0.97      0.97      0.97      3266\n","\n","Accuracy at holdout: 0.9745866503368035\n","Precision at holdout: 0.9737163814180929\n","Recall at holdout: 0.9755052051439069\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aMfYjiRGSOIm","colab_type":"text"},"source":["**Observation**:\n","Logistic performs really well in training and holdout as it predicts low false positives (97.37% precision for winning (1) and 97.37% recall for losing (0)). "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4gL0_r0S0n78"},"source":["### Implement Naive Bayes classifier"]},{"cell_type":"markdown","metadata":{"id":"mitRtr98SOIp","colab_type":"text"},"source":["The Na√Øve Bayes classifier is a simple probabilistic classifier which is based on Bayes theorem but with strong assumptions regarding independence."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FfGR09-K0n78","outputId":"ddfdbbd9-6578-496a-c760-965dad0f9438","colab":{}},"source":["# fit the Gaussian Naive Bayes classifier\n","NBclassifier = GaussianNB()\n","\n","# 5-fold cross validation on Naive Bayes\n","scores = cross_val_score(NBclassifier, \n","                        scaledtrain_teamX, \n","                        train_teamY, cv=5)\n","\n","print('Average train accuracy from cv:', scores.mean())\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Average train accuracy from cv: 0.9620734908136482\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yrmgMEgQSOIz","colab_type":"code","outputId":"1252455e-9643-4792-f9ac-7544246e8c52","colab":{}},"source":["# train classifier with train dataset\n","NBclassifier.fit(scaledtrain_teamX, train_teamY)\n","\n","NB_train_accuracy = NBclassifier.score(scaledtrain_teamX, train_teamY)\n","\n","print('Accuracy on training set: {:.4f}'.format(NB_train_accuracy ))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy on training set: 0.9621\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"n3XmXGcHSOI4","colab_type":"text"},"source":["Model evaluation on test"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eAW37QG30n7_","outputId":"f2533c49-2c5a-44e5-fbf3-06728910f13d","colab":{"base_uri":"https://localhost:8080/","height":290}},"source":["# get the predicted y of the model on the test dataset\n","NB_y_pred = NBclassifier.predict(scaledtest_teamX)\n","\n","# generation confusion matrix and classification report\n","\n","NB_result = pd.DataFrame(confusion_matrix(test_teamY, NB_y_pred),\n","                        index=NBclassifier.classes_, \n","                         columns=NBclassifier.classes_)\n","print(\"Confusion Matrix:\")\n","print(NB_result)\n","NB_result1 = classification_report(test_teamY, NB_y_pred)\n","print(\"Classification Report:\",)\n","print (NB_result1)\n","NB_result2 = accuracy_score(test_teamY, NB_y_pred)\n","print(\"Accuracy at holdout:\", NB_result2) \n","NB_precision = precision_score(test_teamY, NB_y_pred)\n","print(\"Precision at holdout:\", NB_precision)\n","NB_recall = recall_score(test_teamY, NB_y_pred)\n","print(\"Recall at holdout:\", NB_recall)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Confusion Matrix:\n","      0     1\n","0  1561    72\n","1    55  1578\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.96      0.96      1633\n","           1       0.96      0.97      0.96      1633\n","\n","    accuracy                           0.96      3266\n","   macro avg       0.96      0.96      0.96      3266\n","weighted avg       0.96      0.96      0.96      3266\n","\n","Accuracy at holdout: 0.9611145131659522\n","Precision at holdout: 0.9563636363636364\n","Recall at holdout: 0.966319657072872\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Rs3oMPwvSOI_","colab_type":"text"},"source":["**Observation**:\n","\n","Accuracy, precision and recall in training and holdout are lower than logistic. False positives is higher causing precision to be lower and recall. Overall accuracy is also lower than logistic (lower true negatives and true positives.\n","\n","\n","This is probably due to Naive Bayes's assumption of independence among predictors which is not true for this dataset"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"R-ET1tbR0n8A"},"source":["### Implement KNN classifier"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jl181Yn2Kkat"},"source":["KNN will be implemented with stratified K-fold to ensure sampling of data for each fold is a good representative of the binary response variable, which is close to 50% win and 50% loss of matches."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Q_1fzW1Z0n8B","outputId":"c6ade670-05d5-49da-f795-c06fce81607d","colab":{"base_uri":"https://localhost:8080/","height":468}},"source":["# try K=1 through K=15 and record accuracy via 5-Stratfied K-fold cross-validation\n","k_range = range(1, 15)\n","skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=23)\n","# Store accuracy results in a list\n","cross_valid_scores = []\n","\n","for i in k_range:\n","    classifier = KNeighborsClassifier(n_neighbors = i)\n","    scores = cross_val_score(classifier, scaledtrain_teamX, train_teamY, cv=skfold)\n","    cross_valid_scores.append(np.mean(scores))\n","    \n","accuracy_list = pd.DataFrame({\n","    'K_value' : k_range,\n","    'Cross_validation_accuracy' : cross_valid_scores \n","})\n","accuracy_list"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>K_value</th>\n","      <th>Cross_validation_accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0.954462</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0.950787</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0.964698</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0.964567</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0.965354</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>0.965092</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>0.965879</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>0.967192</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>0.968110</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>0.967717</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>11</td>\n","      <td>0.968635</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>12</td>\n","      <td>0.969029</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>13</td>\n","      <td>0.970079</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>14</td>\n","      <td>0.971522</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    K_value  Cross_validation_accuracy\n","0         1                   0.954462\n","1         2                   0.950787\n","2         3                   0.964698\n","3         4                   0.964567\n","4         5                   0.965354\n","5         6                   0.965092\n","6         7                   0.965879\n","7         8                   0.967192\n","8         9                   0.968110\n","9        10                   0.967717\n","10       11                   0.968635\n","11       12                   0.969029\n","12       13                   0.970079\n","13       14                   0.971522"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"F8eZxzqm0n8D","outputId":"a3dde071-cd00-4014-8c2e-665d4a1cdfe6","colab":{"base_uri":"https://localhost:8080/","height":297}},"source":["# plot the relationship between K and testing accuracy\n","plt.plot(k_range, cross_valid_scores)\n","plt.xlabel('K value used for KNN')\n","plt.ylabel('Testing Accuracy at Train')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0, 0.5, 'Testing Accuracy at Train')"]},"metadata":{"tags":[]},"execution_count":18},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"c9PqRUUpSOJR","colab_type":"text"},"source":["Best k through model optimization is 9."]},{"cell_type":"markdown","metadata":{"id":"GRV-uei6SOJT","colab_type":"text"},"source":["Fit model on training set"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dtQ1201e0n8H","outputId":"aebcd765-4e4d-41b2-b244-37c05859e470","colab":{}},"source":["# fit the classifier for n_neighbors = 9\n","KNNclassifier = KNeighborsClassifier(n_neighbors = 9)\n","KNNclassifier.fit(scaledtrain_teamX, train_teamY)\n","\n","KNN_train_accuracy = KNNclassifier.score(scaledtrain_teamX, train_teamY)\n","print('Accuracy on training set: {:.4f}'.format(KNN_train_accuracy ))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy on training set: 0.9747\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BkDlZDhpSOJZ","colab_type":"text"},"source":["Model evaluation on test"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OECqp5fc0n8K","outputId":"33947532-1234-4b88-9544-68d78d6da5b8","colab":{"base_uri":"https://localhost:8080/","height":290}},"source":["# get the predicted y of the model\n","KNN_y_pred = KNNclassifier.predict(scaledtest_teamX)\n","\n","KNN_result = pd.DataFrame(confusion_matrix(test_teamY, KNN_y_pred),\n","                             index=KNNclassifier.classes_, columns=KNNclassifier.classes_)\n","print(\"Confusion Matrix:\")\n","print(KNN_result)\n","KNN_result1 = classification_report(test_teamY, KNN_y_pred)\n","print(\"Classification Report:\",)\n","print (KNN_result1)\n","KNN_result2 = accuracy_score(test_teamY, KNN_y_pred)\n","print(\"Accuracy at holdout:\", KNN_result2)  \n","KNN_precision = precision_score(test_teamY, KNN_y_pred)\n","print(\"Precision at holdout:\", KNN_precision)\n","KNN_recall = recall_score(test_teamY, KNN_y_pred)\n","print(\"Recall at holdout:\", KNN_recall)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Confusion Matrix:\n","      0     1\n","0  1573    60\n","1    47  1586\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.96      0.97      1633\n","           1       0.96      0.97      0.97      1633\n","\n","    accuracy                           0.97      3266\n","   macro avg       0.97      0.97      0.97      3266\n","weighted avg       0.97      0.97      0.97      3266\n","\n","Accuracy at holdout: 0.9672382118799755\n","Precision at holdout: 0.9635479951397327\n","Recall at holdout: 0.9712186160440907\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZOHgdOaISOJg","colab_type":"text"},"source":["**Observations**:\n","Though KNN classifier performs better in training and test better than NB classifier as it has higher accuracy, precision and recall. However, KNN classifier does not perform as well as Logistic in all of the areas. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"u3wphrFi0n8M"},"source":["### Implement Random Forest classifier"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"yd8F0Q4SLr9d"},"source":["Random Forest classifier will be optimized using GridSearch (with 5 k-folds) to determine optimal values for max features (number of features to be considered when looking for best split), minimum samples leaf (minimum proportion of samples to be at a leaf node) and maximum depth of the tree. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UHisimv30n8M","outputId":"4c378de1-2c42-476f-df49-818c0dfe1bed","colab":{"base_uri":"https://localhost:8080/","height":431}},"source":["# Initialize the Kfold cross validation\n","skfold = KFold(n_splits=5, shuffle=True, random_state=23)\n","\n","# Initialize the set of parameters for exhaustive search and fit \n","parameters = {'max_features': [2, 4, 5, 6, 8], \n","              'min_samples_leaf': [1, 3, 4, 5, 7], \n","              'max_depth': [5,7,8,9,10]}\n","\n","# implement randomforest with 100 trees\n","rforestclassifier = RandomForestClassifier(n_estimators=100, \n","                                           random_state=23, n_jobs=-1)\n","\n","#GridSearch to find the optimal parameters for our example:\n","gcv = GridSearchCV(rforestclassifier, parameters, n_jobs=-1, cv=skfold, \n","                   verbose=1)\n","gcv.fit(scaledtrain_teamX, train_teamY)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Fitting 5 folds for each of 125 candidates, totalling 625 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    5.3s\n","[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   19.5s\n","[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   48.3s\n","[Parallel(n_jobs=-1)]: Done 625 out of 625 | elapsed:  1.2min finished\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=KFold(n_splits=5, random_state=23, shuffle=True),\n","             error_score='raise-deprecating',\n","             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n","                                              criterion='gini', max_depth=None,\n","                                              max_features='auto',\n","                                              max_leaf_nodes=None,\n","                                              min_impurity_decrease=0.0,\n","                                              min_impurity_split=None,\n","                                              min_samples_leaf=1,\n","                                              min_samples_split=2,\n","                                              min_weight_fraction_leaf=0.0,\n","                                              n_estimators=100, n_jobs=-1,\n","                                              oob_score=False, random_state=23,\n","                                              verbose=0, warm_start=False),\n","             iid='warn', n_jobs=-1,\n","             param_grid={'max_depth': [5, 7, 8, 9, 10],\n","                         'max_features': [2, 4, 5, 6, 8],\n","                         'min_samples_leaf': [1, 3, 4, 5, 7]},\n","             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n","             scoring=None, verbose=1)"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"17R2dh-E0n8O","outputId":"f97c4074-a77e-4476-c54e-9901aeff91b9","colab":{}},"source":["print('Best parameters:', gcv.best_params_) \n","print('Accuracy at train:',gcv.best_score_)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Best parameters: {'max_depth': 8, 'max_features': 6, 'min_samples_leaf': 4}\n","Accuracy at train: 0.9744094488188977\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Sk64kYRySOJu","colab_type":"text"},"source":["Train random forest model using best parameters"]},{"cell_type":"code","metadata":{"id":"hW5efp-cSOJv","colab_type":"code","outputId":"9163d56f-0aaa-4c99-f917-946c9fb718bf","colab":{}},"source":["gcv = RandomForestClassifier(n_estimators=100, random_state=23, \n","                            n_jobs=-1, max_depth=8, max_features=6, \n","                            min_samples_leaf=4)\n","gcv.fit(scaledtrain_teamX, train_teamY)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n","                       max_depth=8, max_features=6, max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=4, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=100,\n","                       n_jobs=-1, oob_score=False, random_state=23, verbose=0,\n","                       warm_start=False)"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"Sor5ewSESOJy","colab_type":"code","outputId":"c2e94abb-df08-40ab-caf4-22572bb96d42","colab":{}},"source":["# get accuracy of model on training set\n","RF_train_accuracy = gcv.score(scaledtrain_teamX, train_teamY)\n","print('Accuracy on training set: {:.4f}'.format(RF_train_accuracy ))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy on training set: 0.9877\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UQd-_RxhSOJ2","colab_type":"text"},"source":["Evaluating trained Random Forest model on test"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1n1lpdZt0n8R","colab":{}},"source":["# get the predicted y of the model\n","rfc_y_pred = gcv.predict(scaledtest_teamX)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JGdh37Zb0n8T","outputId":"15e6a654-9a50-4985-8c7b-ca6f9054f453","colab":{}},"source":["rfc_result = pd.DataFrame(confusion_matrix(test_teamY, rfc_y_pred),\n","                             index=gcv.classes_, columns=gcv.classes_)\n","print(\"Confusion Matrix:\")\n","print(rfc_result)\n","rfc_result1 = classification_report(test_teamY, rfc_y_pred)\n","print(\"Classification Report:\",)\n","print (rfc_result1)\n","rfc_result2 = accuracy_score(test_teamY, rfc_y_pred)\n","print(\"Accuracy for holdout:\", rfc_result2) \n","rfc_precision = precision_score(test_teamY, rfc_y_pred)\n","print(\"Precision at holdout:\", rfc_precision)\n","rfc_recall = recall_score(test_teamY, rfc_y_pred)\n","print(\"Recall at holdout:\", rfc_recall)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Confusion Matrix:\n","      0     1\n","0  1577    56\n","1    39  1594\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.97      0.97      1633\n","           1       0.97      0.98      0.97      1633\n","\n","    accuracy                           0.97      3266\n","   macro avg       0.97      0.97      0.97      3266\n","weighted avg       0.97      0.97      0.97      3266\n","\n","Accuracy for holdout: 0.9709124311083894\n","Precision at holdout: 0.9660606060606061\n","Recall at holdout: 0.9761175750153093\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VeM54Kr5SOJ-","colab_type":"code","outputId":"a6fd8750-398f-47dd-b545-7096e28017b5","colab":{}},"source":["names = Teams_df.columns\n","print (\"Features sorted by its score:\", \n","       sorted(zip(map(lambda x: round(x, 5), \n","                     gcv.feature_importances_), names), \n","             reverse=True))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Features sorted by its score: [(0.67919, 'teamtowerkills'), (0.15774, 'kpm'), (0.1271, 'd'), (0.00824, 'minionkills'), (0.00742, 'elementals'), (0.0071, 'gdiffat15'), (0.00516, 'wcpm'), (0.00367, 'xpat10'), (0.00353, 'fbarontime'), (0.00086, 'ft')]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"69JuDJ0uSOKB","colab_type":"text"},"source":["**Observations**:\n","1. Random forest picks teamtowerkills and kpm (kills per minutes) as top features, while the rest of features have relatively similar importance. \n","\n","\n","2. Random Forest performs better than naive bayes, and KNN in terms of overall accuracy, precision and recall for winning and losing due to identifying lesser false positives and negatives. However, false positives identified are still higher than logistic due to lower true negatives than logistic. This caused random forest to have slightly lower overall accuracy than logistic"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Y6GwvuG90n8V"},"source":["### Bagging on logistic, KNN, and Decision Tree"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zvWC241j0n8W"},"source":["Bagging stands for bootstrap aggregation. One way to reduce the variance of an estimate is to average together multiple estimates. For example, we can train $M$ different trees $f_m$ on different subsets of the data (chosen randomly with replacement) and compute the ensemble:\n","\\begin{equation}\n","   f(x) = \\frac{1}{M}\\sum_{m=1}^{M}f_m(x) \n","\\end{equation}\n","\n","Bagging uses bootstrap sampling to obtain the data subsets for training the base learners. For aggregating the outputs of base learners, bagging uses voting for classification and averaging for regression."]},{"cell_type":"code","metadata":{"id":"RVYrV9mySOKD","colab_type":"code","outputId":"38712caf-e4b4-4fc7-d962-85af9bcb542d","colab":{}},"source":["# Tune decision tree using training set\n","\n","# Initialize the 5 Kfold cross validation\n","skfold = KFold(n_splits=5, shuffle=True, random_state=23)\n","\n","# Initialize the set of parameters for exhaustive search and fit \n","parameters = {'max_features': [2, 4, 5, 6, 8], \n","              'min_samples_leaf': [1, 3, 4, 5, 7], \n","              'max_depth': [5,7,8,9,10]}\n","\n","# implement Decision Tree\n","DT = DecisionTreeClassifier(random_state=23)\n","\n","#GridSearch to find the optimal parameters for our example:\n","DT_search = GridSearchCV(DT, parameters, n_jobs=-1, cv=skfold, \n","                   verbose=1)\n","DT_search.fit(scaledtrain_teamX, train_teamY)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Fitting 5 folds for each of 125 candidates, totalling 625 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.6s\n","[Parallel(n_jobs=-1)]: Done 625 out of 625 | elapsed:    4.8s finished\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=KFold(n_splits=5, random_state=23, shuffle=True),\n","             error_score='raise-deprecating',\n","             estimator=DecisionTreeClassifier(class_weight=None,\n","                                              criterion='gini', max_depth=None,\n","                                              max_features=None,\n","                                              max_leaf_nodes=None,\n","                                              min_impurity_decrease=0.0,\n","                                              min_impurity_split=None,\n","                                              min_samples_leaf=1,\n","                                              min_samples_split=2,\n","                                              min_weight_fraction_leaf=0.0,\n","                                              presort=False, random_state=23,\n","                                              splitter='best'),\n","             iid='warn', n_jobs=-1,\n","             param_grid={'max_depth': [5, 7, 8, 9, 10],\n","                         'max_features': [2, 4, 5, 6, 8],\n","                         'min_samples_leaf': [1, 3, 4, 5, 7]},\n","             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n","             scoring=None, verbose=1)"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"YMuL5_9YSOKH","colab_type":"code","outputId":"efc6abf7-2d01-441c-cb53-7dfc646a21ed","colab":{}},"source":["print('Best parameters:', DT_search.best_params_) \n","print('Accuracy at train:',DT_search.best_score_)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Best parameters: {'max_depth': 5, 'max_features': 8, 'min_samples_leaf': 7}\n","Accuracy at train: 0.9694225721784777\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FXIhecO0SOKJ","colab_type":"text"},"source":["Train decision tree with best parameters"]},{"cell_type":"code","metadata":{"id":"gfl9MOIiSOKK","colab_type":"code","outputId":"a5223506-6d18-4291-d7c1-b659ff1a8da6","colab":{}},"source":["DT = DecisionTreeClassifier(random_state=23, \n","                            max_depth=5, max_features=8, \n","                            min_samples_leaf=7)\n","DT.fit(scaledtrain_teamX, train_teamY)\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n","                       max_features=8, max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=7, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, presort=False,\n","                       random_state=23, splitter='best')"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"v9vlwvbASOKN","colab_type":"text"},"source":["Try fit bagging on logistic, tuned KNN classifier, and tuned Decision Tree on training set"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rsVT6RP20n8W","colab":{}},"source":["clf1 = logreg\n","clf2 = KNNclassifier  \n","clf3 = DT\n","\n","bagging1 = BaggingClassifier(base_estimator=clf1, \n","                             n_estimators=100, max_samples=0.7, \n","                             max_features=0.8)\n","bagging2 = BaggingClassifier(base_estimator=clf2, \n","                             n_estimators=100, max_samples=0.7, \n","                             max_features=0.8)\n","bagging3 = BaggingClassifier(base_estimator=clf3, \n","                             n_estimators=100, max_samples=0.7, \n","                             max_features=0.8)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"n6Z5cVTT0n8Z","outputId":"51889db0-4ebf-449b-c228-640c5d20f430","colab":{}},"source":["# conduct 5-fold cross validation on bagging\n","\n","label = ['Logistic', 'K-NN', 'Decision Tree', \n","         'Bagging Logistic','Bagging K-NN', 'Bagging Tree']\n","clf_list = [clf1, clf2, clf3, bagging1, bagging2, bagging3]\n","\n","for clf, label in zip(clf_list, label):        \n","    scores = cross_val_score(clf, np.array(scaledtrain_teamX), \n","                             np.array(train_teamY), cv=5, \n","                             scoring='accuracy')\n","    print (\"Accuracy for train:\", scores.mean(), scores.std(), label)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy for train: 0.9784776902887138 0.0024691453703709855 Logistic\n","Accuracy for train: 0.96745406824147 0.003950109433934996 K-NN\n","Accuracy for train: 0.9658792650918635 0.0026246719160105013 Decision Tree\n","Accuracy for train: 0.9770341207349083 0.002383976656769668 Bagging Logistic\n","Accuracy for train: 0.970734908136483 0.00338674223111916 Bagging K-NN\n","Accuracy for train: 0.9725721784776903 0.0012723569179570364 Bagging Tree\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1kCOaqpB0n8a"},"source":["Bagging does improve KNN and decision tree model but still performs not as good as normal Logistic"]},{"cell_type":"markdown","metadata":{"id":"kMzuOIjHSOKT","colab_type":"text"},"source":["Model evaluation of bagging KNN on train and test"]},{"cell_type":"code","metadata":{"id":"yVihW4svSOKU","colab_type":"code","outputId":"27a54097-c28c-4d5c-8391-157e60a60c2a","colab":{}},"source":["# model accuracy on training set\n","bagging2.fit(scaledtrain_teamX, train_teamY)\n","bKNN_train_accuracy = bagging2.score(scaledtrain_teamX, train_teamY)\n","print('Accuracy on training set: {:.4f}'.format(bKNN_train_accuracy ))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy on training set: 0.9774\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"f2p7YrP70n8a","outputId":"b3ad0501-bf08-4d08-afcb-2862a691386e","colab":{}},"source":["# result of Bagging KNN on test\n","bKNN_y_pred = bagging2.predict(scaledtest_teamX)\n","\n","bKNN_result = pd.DataFrame(confusion_matrix(test_teamY, bKNN_y_pred), \n","                           index=bagging2.classes_,\n","                          columns=bagging2.classes_)\n","print(\"Confusion Matrix:\")\n","print(bKNN_result)\n","bKNN_result1 = classification_report(test_teamY, bKNN_y_pred)\n","print(\"Classification Report:\",)\n","print (bKNN_result1)\n","bKNN_result2 = accuracy_score(test_teamY, bKNN_y_pred)\n","print(\"Accuracy for holdout:\", bKNN_result2) \n","bKNN_precision = precision_score(test_teamY, bKNN_y_pred)\n","print(\"Precision at holdout:\", bKNN_precision)\n","bKNN_recall = recall_score(test_teamY, bKNN_y_pred)\n","print(\"Recall at holdout:\", bKNN_recall)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Confusion Matrix:\n","      0     1\n","0  1572    61\n","1    37  1596\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.96      0.97      1633\n","           1       0.96      0.98      0.97      1633\n","\n","    accuracy                           0.97      3266\n","   macro avg       0.97      0.97      0.97      3266\n","weighted avg       0.97      0.97      0.97      3266\n","\n","Accuracy for holdout: 0.969993876301286\n","Precision at holdout: 0.9631864815932408\n","Recall at holdout: 0.977342314758114\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aY-RRlFfSOKc","colab_type":"text"},"source":["Model evaluation of bagging decision tree on train and test"]},{"cell_type":"code","metadata":{"id":"ybvT2vu9SOKd","colab_type":"code","outputId":"07a63c90-7cd9-4ed8-8573-70097d3dc525","colab":{}},"source":["# model accuracy on training set\n","bagging3.fit(scaledtrain_teamX, train_teamY)\n","bdtree_train_accuracy = bagging3.score(scaledtrain_teamX, train_teamY)\n","print('Accuracy on training set: {:.4f}'.format(bdtree_train_accuracy ))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy on training set: 0.9781\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qMwXe6vCSOKh","colab_type":"code","outputId":"30b82282-0437-4ebc-e23b-7b84b5e1d106","colab":{}},"source":["# validate train model on test set\n","\n","bdtree_y_pred = bagging3.predict(scaledtest_teamX)\n","\n","bdtree_result = pd.DataFrame(confusion_matrix(test_teamY, bdtree_y_pred), \n","                             index=bagging3.classes_,\n","                          columns=bagging3.classes_)\n","print(\"Confusion Matrix:\")\n","print(bdtree_result)\n","bdtree_result1 = classification_report(test_teamY, bdtree_y_pred)\n","print(\"Classification Report:\",)\n","print (bdtree_result1)\n","bdtree_result2 = accuracy_score(test_teamY, bdtree_y_pred)\n","print(\"Accuracy for holdout:\", bdtree_result2) \n","bdtree_precision = precision_score(test_teamY, bdtree_y_pred)\n","print(\"Precision at holdout:\", bdtree_precision)\n","bdtree_recall = recall_score(test_teamY, bdtree_y_pred)\n","print(\"Recall at holdout:\", bdtree_recall)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Confusion Matrix:\n","      0     1\n","0  1572    61\n","1    28  1605\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.96      0.97      1633\n","           1       0.96      0.98      0.97      1633\n","\n","    accuracy                           0.97      3266\n","   macro avg       0.97      0.97      0.97      3266\n","weighted avg       0.97      0.97      0.97      3266\n","\n","Accuracy for holdout: 0.9727495407225965\n","Precision at holdout: 0.9633853541416567\n","Recall at holdout: 0.9828536436007348\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tXMFMvt7SOKl","colab_type":"text"},"source":["**Observations**:\n","\n","In holdout, Bagging KNN generates higher recall (due to lower false negatives) (but high false positives than KNN without bagging) while bagging Decision Tree generates higher true positives and lesser false negatives than other models (higher recall). Yet, both overall accuracies are still lower than Logistic due to higher false positives (lower precision)"]},{"cell_type":"markdown","metadata":{"id":"Bp9KEM0pSOKm","colab_type":"text"},"source":["### Adaboosting classifier"]},{"cell_type":"markdown","metadata":{"id":"c2ey-VyTSOKm","colab_type":"text"},"source":["We will now be using adaboost (adaptive boosting)classification on base learner, which is decision tree "]},{"cell_type":"markdown","metadata":{"id":"OqLonar0SOKn","colab_type":"text"},"source":["Classifier will be tuned in 5-folds using n_estimator and learning rate: \n","- n_estimators refer to maximum number of estimators at which boosting is terminated\n","- learning rate refers how much the contribution of each classifiers is shrinked by"]},{"cell_type":"code","metadata":{"id":"IeR1LA6QSOKp","colab_type":"code","colab":{}},"source":["ada=AdaBoostClassifier()\n","ada_search_grid={'n_estimators':[500,1000,1500,2000],\n","                 'learning_rate':[.001,0.01,.1]}\n","\n","ada_search=GridSearchCV(estimator=ada,\n","                        param_grid=ada_search_grid, \n","                        scoring='accuracy',n_jobs=-1,cv=5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W6MQsYMdSOKr","colab_type":"code","outputId":"a953dea3-a89c-4df4-9e6c-33ff2b16c3b3","colab":{}},"source":["ada_search.fit(scaledtrain_teamX, train_teamY)\n","print(ada_search.best_params_)\n","print('Accuracy for train:', ada_search.best_score_)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{'learning_rate': 0.01, 'n_estimators': 2000}\n","Accuracy for train: 0.9753280839895013\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gk1dpUG6SOKt","colab_type":"code","outputId":"87bca8ca-707b-458d-b3d0-0f6cd69bb9a3","colab":{}},"source":["# train model with best parameters\n","ada_best = AdaBoostClassifier(n_estimators=2000, \n","                              learning_rate = 0.01, random_state=23)\n","ada_best.fit(scaledtrain_teamX, train_teamY)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.01,\n","                   n_estimators=2000, random_state=23)"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"si9MFclCSOKw","colab_type":"code","outputId":"142abba3-a104-455f-fbdc-3c4b64798af2","colab":{}},"source":["# model accuracy on training set\n","\n","ada_train_accuracy = ada_best.score(scaledtrain_teamX, train_teamY)\n","print('Accuracy on training set: {:.4f}'.format(ada_train_accuracy ))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy on training set: 0.9766\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wJO70PGjSOK0","colab_type":"text"},"source":["Use trained model for validation on holdout"]},{"cell_type":"code","metadata":{"id":"0roOf4hWSOK0","colab_type":"code","outputId":"4d27d63c-75dc-41fe-dbda-e86c8e7d149e","colab":{}},"source":["ada_y_pred = ada_best.predict(scaledtest_teamX)\n","\n","ada_result = pd.DataFrame(confusion_matrix(test_teamY, ada_y_pred), index=ada_best.classes_,\n","                          columns=ada_best.classes_)\n","print(\"Confusion Matrix:\")\n","print(ada_result)\n","ada_result1 = classification_report(test_teamY, ada_y_pred)\n","print(\"Classification Report:\",)\n","print (ada_result1)\n","ada_result2 = accuracy_score(test_teamY, ada_y_pred)\n","print(\"Accuracy for holdout:\", ada_result2) \n","ada_precision = precision_score(test_teamY, ada_y_pred)\n","print(\"Precision at holdout:\", ada_precision)\n","ada_recall = recall_score(test_teamY, ada_y_pred)\n","print(\"Recall at holdout:\", ada_recall)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Confusion Matrix:\n","      0     1\n","0  1580    53\n","1    32  1601\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.97      0.97      1633\n","           1       0.97      0.98      0.97      1633\n","\n","    accuracy                           0.97      3266\n","   macro avg       0.97      0.97      0.97      3266\n","weighted avg       0.97      0.97      0.97      3266\n","\n","Accuracy for holdout: 0.9739742804654011\n","Precision at holdout: 0.967956469165659\n","Recall at holdout: 0.9804041641151255\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GZa8XFjcSOK2","colab_type":"text"},"source":["**Observation**:\n","\n","Adaboosting Classifier performs better in precision than other models due to lesser false positives (only higher than Logistic). It also has high recall (just lower than bagging decision tree) due to low false negatives.\n","\n","Overall accuracy is higher than other models but lower than Logistic. \n","However, boosting has proved to achieve higher accuracy than bagging for Decision Tree (higher true negatives and lower false positives), reducing bias in Decision Tree"]},{"cell_type":"markdown","metadata":{"id":"Bm3Hmd4SSOK3","colab_type":"text"},"source":["### Implement Multi Layer Perceptron"]},{"cell_type":"markdown","metadata":{"id":"pd29BL16SOK4","colab_type":"text"},"source":["Multilayer perceptron (MLP) is a supervised neural network model. It is composed of more than one perceptron. They are composed of an input layer to receive the signal, an output layer that makes a decision or prediction about the input, and in between those two, an arbitrary number of hidden layers that are the true computational engine of the MLP. MLPs with one hidden layer are capable of approximating any continuous function.\n","\n","- hidden_layer_sizes : This parameter allows us to set the number of layers and the number of nodes we wish to have in the Neural Network Classifier. Each element in the tuple represents the number of nodes at the ith position where i is the index of the tuple. Thus the length of tuple denotes the total number of hidden layers in the network.\n","- max_iter: It denotes the number of epochs (cycle through full dataset).\n","- activation: The activation function for the hidden layers.\n","- alpha: L2 penalty (regularization term) parameter\n","- solver: This parameter specifies the algorithm for weight optimization across the nodes.\n","- random_state: The parameter allows to set a seed for reproducing the same results"]},{"cell_type":"code","metadata":{"id":"f6833jScSOK4","colab_type":"code","colab":{}},"source":["#Importing MLPClassifier\n","from sklearn.neural_network import MLPClassifier"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pD_yOkRHSOLB","colab_type":"code","outputId":"2f135096-0fd0-4bce-8dad-b47e3beeb1c1","colab":{}},"source":["# tune multi layer perceptron using training set\n","\n","# tune parameters with 5 fold cross validation\n","\n","parameters = {'solver': ['lbfgs'], \n","              'activation': ['logistic','relu'],\n","              'max_iter': [500, 550, 600, 700, 800], \n","              'alpha': 10.0 ** -np.arange(1, 5), \n","              'hidden_layer_sizes':np.arange(6, 10)}\n","\n","mlp= GridSearchCV(MLPClassifier(random_state=23), \n","                  parameters, n_jobs=-1, cv=5)\n","\n","mlp.fit(scaledtrain_teamX, train_teamY)\n","print(mlp.score(scaledtrain_teamX, train_teamY))\n","print(mlp.best_params_)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.9805774278215224\n","{'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': 7, 'max_iter': 500, 'solver': 'lbfgs'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Jo4OBBdsSOLD","colab_type":"code","outputId":"b0c1eaea-a496-456e-a412-0e876691c089","colab":{}},"source":["# train momodel with best params\n","mlp = MLPClassifier(solver='lbfgs', max_iter=500, \n","                    alpha=0.1, hidden_layer_sizes=7,\n","                   random_state=23)\n","mlp.fit(scaledtrain_teamX, train_teamY)\n","\n","mlp_score = np.mean(train_teamY == mlp.predict(scaledtrain_teamX))\n","print('Accuracy for train:', mlp_score)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy for train: 0.9805774278215224\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"24MLUE9GSOLG","colab_type":"code","outputId":"b5ee03cc-29b6-4501-8dd3-2b323730d9fd","colab":{}},"source":["# validating model in holdout\n","\n","mlp_y_pred =  mlp.predict(scaledtest_teamX)\n","\n","mlp_result = pd.DataFrame(confusion_matrix(test_teamY, mlp_y_pred), \n","                          index=mlp.classes_,\n","                           columns=mlp.classes_)\n","print(\"Confusion Matrix:\")\n","print(mlp_result)\n","mlp_result1 = classification_report(test_teamY, mlp_y_pred)\n","print(\"Classification Report:\",)\n","print (mlp_result1)\n","mlp_result2 = accuracy_score(test_teamY, mlp_y_pred)\n","print(\"Accuracy for holdout:\", mlp_result2) \n","mlp_precision = precision_score(test_teamY, mlp_y_pred)\n","print(\"Precision at holdout:\", mlp_precision)\n","mlp_recall = recall_score(test_teamY, mlp_y_pred)\n","print(\"Recall at holdout:\", mlp_recall)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Confusion Matrix:\n","      0     1\n","0  1585    48\n","1    38  1595\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.97      0.97      1633\n","           1       0.97      0.98      0.97      1633\n","\n","    accuracy                           0.97      3266\n","   macro avg       0.97      0.97      0.97      3266\n","weighted avg       0.97      0.97      0.97      3266\n","\n","Accuracy for holdout: 0.9736680955296999\n","Precision at holdout: 0.970785149117468\n","Recall at holdout: 0.9767299448867116\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-xV8oFQDSOLI","colab_type":"text"},"source":["**Observations**:\n","\n","Multi layer perceptron has the second highest accuracy (below Adaboost) among all individual models. While it has second highest precision after Logistic, it is also the 4th highest in recall after Adaboost, Bagging Decision Tree, and Bagging KNN.\n","Overall, its performance is well-balanced in all areas. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"q5MMbcVR0n8e"},"source":["### Ensemble Voting Classifier"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"b0zT_pA40n8e"},"source":["The EnsembleVoteClassifier is a meta-classifier for combining similar or conceptually different machine learning classifiers for classification via majority or plurality voting. (For simplicity, we will refer to both majority and plurality voting as majority voting.)\n","\n","The EnsembleVoteClassifier implements \"hard\" and \"soft\" voting. In hard voting, we predict the final class label as the class label that has been predicted most frequently by the classification models. In soft voting, we predict the class labels by averaging the class-probabilities (only recommended if the classifiers are well-calibrated)."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UnO_zJjL0n8f","colab":{}},"source":["# using pre-fitted classifiers\n","# models used in this ensemble (which produces the best precision): \n","# logreg, random forest, adaboost, multilayer perceptron\n","\n","clf1 = logreg\n","clf2 = gcv  #random forest (grid search)\n","clf3 = ada_best #adaboost\n","clf4 = mlp # multi layer perceptron"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dlPB1yOJ0n8h","outputId":"c7df4936-de38-47c9-ed23-8e4c1f5e6275","colab":{}},"source":["# By setting refit=False, \n","# the EnsembleVoteClassifier will not re-fit these classifers to save computational time\n","\n","eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3, clf4], \n","                              weights=[1,1,1,1], \n","                              refit=False)\n","\n","eclf.fit(scaledtrain_teamX, train_teamY)\n","\n","Voting_score = np.mean(train_teamY == eclf.predict(scaledtrain_teamX))\n","print('accuracy for train:', Voting_score)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["accuracy for train: 0.981496062992126\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yh0AW0nISOLO","colab_type":"text"},"source":["Model validation for ensemble voting classifier"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"81vWjs900n8i","outputId":"d98da06e-1759-4670-ae17-76557af13c83","colab":{}},"source":["eclf_y_pred = eclf.predict(scaledtest_teamX)\n","\n","eclf_result = pd.DataFrame(confusion_matrix(test_teamY, eclf_y_pred), index=eclf.classes_,\n","                           columns=eclf.classes_)\n","print(\"Confusion Matrix:\")\n","print(eclf_result)\n","eclf_result1 = classification_report(test_teamY, eclf_y_pred)\n","print(\"Classification Report:\",)\n","print (eclf_result1)\n","eclf_result2 = accuracy_score(test_teamY, eclf_y_pred)\n","print(\"Accuracy for holdout:\", eclf_result2) \n","eclf_precision = precision_score(test_teamY, eclf_y_pred)\n","print(\"Precision at holdout:\", eclf_precision)\n","eclf_recall = recall_score(test_teamY, eclf_y_pred)\n","print(\"Recall at holdout:\", eclf_recall)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Confusion Matrix:\n","      0     1\n","0  1592    41\n","1    38  1595\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.97      0.98      1633\n","           1       0.97      0.98      0.98      1633\n","\n","    accuracy                           0.98      3266\n","   macro avg       0.98      0.98      0.98      3266\n","weighted avg       0.98      0.98      0.98      3266\n","\n","Accuracy for holdout: 0.975811390079608\n","Precision at holdout: 0.9749388753056235\n","Recall at holdout: 0.9767299448867116\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BBGdfuXoSOLQ","colab_type":"text"},"source":["**Observations**:\n","Ensemble voting classifiers performs better in the holdout than all individual models. \n","Ensemble voting performs better than Logistic in generating higher winning predictions and lower false negatives for winning. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HU_vw8jI0n8j"},"source":["### Implement Stacked Classsification and cross validation"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"59V94hld0n8k"},"source":["Stacking is an ensemble learning technique to combine multiple classification models via a meta-classifier. The StackingCVClassifier extends the standard stacking algorithm (implemented as StackingClassifier) using cross-validation to prepare the input data for the level-2 classifier.\n","\n","In the standard stacking procedure, the first-level classifiers are fit to the same training set that is used prepare the inputs for the second-level classifier, which may lead to overfitting. The StackingCVClassifier, however, uses the concept of cross-validation: the dataset is split into k folds, and in k successive rounds, k-1 folds are used to fit the first level classifier; in each round, the first-level classifiers are then applied to the remaining 1 subset that was not used for model fitting in each iteration. The resulting predictions are then stacked and provided -- as input data -- to the second-level classifier. After the training of the StackingCVClassifier, the first-level classifiers are fit to the entire dataset as illustrated in the figure below."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hdmOnxzs0n8k"},"source":["#### Stacked CV Classification and GridSearch\n","\n","The stack allows tuning hyper parameters of the base and meta models. 3-fold cross-validation will be used for this model"]},{"cell_type":"markdown","metadata":{"id":"suIIKEZ_SOLS","colab_type":"text"},"source":["Logistic as meta classifier with random forest, adaboost and multi layer perceptron as base learners"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_61xDPDx0n8l","outputId":"00b3d1f8-ae5a-4ad2-cbbc-25726141d120","colab":{}},"source":["RANDOM_SEED = 23\n","# models used in this ensemble (which produces the best precision): \n","# logreg, random forest, adaboost, multilayer perceptron\n","\n","lr = logreg #logistic regression will be used as meta classifier\n","clf1 = gcv  #random forest (grid search)\n","clf2 = ada_best #boosting Decision Tree\n","clf3 = mlp #multi-layer perceptron\n","\n","sclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3],\n","                            meta_classifier=lr,\n","                            random_state=RANDOM_SEED)\n","\n","print('3-fold cross validation:\\n')\n","\n","for clf, label in zip([clf1, clf2, clf3, sclf], \n","                      ['Random Forest',\n","                       'Boosting Decision Tree',\n","                       'Multi Layer Perceptron',\n","                       'Stacking Classifier']):\n","\n","    scores = cross_val_score(clf, scaledtrain_teamX, train_teamY, \n","                                              cv=3, scoring='accuracy')\n","    print(\"Accuracy at train: %0.3f (+/- %0.3f) [%s]\" \n","          % (scores.mean(), scores.std(), label))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["3-fold cross validation:\n","\n","Accuracy at train: 0.973 (+/- 0.002) [Random Forest]\n","Accuracy at train: 0.974 (+/- 0.001) [Boosting Decision Tree]\n","Accuracy at train: 0.972 (+/- 0.004) [Multi Layer Perceptron]\n","Accuracy at train: 0.974 (+/- 0.000) [Stacking Classifier]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NowuXYY8SOLZ","colab_type":"text"},"source":["Model validation on training set"]},{"cell_type":"code","metadata":{"id":"na2Rg8BnSOLZ","colab_type":"code","outputId":"34b1c964-0aaf-4451-a7d3-ee81b3ce33cc","colab":{}},"source":["sclf.fit(scaledtrain_teamX, train_teamY)\n","sclf_accuracy = np.mean(train_teamY == sclf.predict(scaledtrain_teamX))\n","print('accuracy at train:', sclf_accuracy)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["accuracy at train: 0.9822834645669292\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rsT-eBxqSOLb","colab_type":"text"},"source":["Model validation on test"]},{"cell_type":"code","metadata":{"id":"FkaAcnKuSOLc","colab_type":"code","outputId":"708eb303-b573-47cf-d53f-0a73b16bed53","colab":{}},"source":["sclf_y_pred = sclf.predict(scaledtest_teamX)\n","\n","sclf_result = pd.DataFrame(confusion_matrix(test_teamY, sclf_y_pred))\n","print(\"Confusion Matrix:\")\n","print(sclf_result)\n","sclf_result1 = classification_report(test_teamY, sclf_y_pred)\n","print(\"Classification Report:\",)\n","print (sclf_result1)\n","sclf_result2 = accuracy_score(test_teamY, sclf_y_pred)\n","print(\"Accuracy at holdout:\", sclf_result2)\n","sclf_precision = precision_score(test_teamY, sclf_y_pred)\n","print(\"Precision at holdout:\", sclf_precision)\n","sclf_recall = recall_score(test_teamY, sclf_y_pred)\n","print(\"Recall at holdout:\", sclf_recall)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Confusion Matrix:\n","      0     1\n","0  1578    55\n","1    33  1600\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.97      0.97      1633\n","           1       0.97      0.98      0.97      1633\n","\n","    accuracy                           0.97      3266\n","   macro avg       0.97      0.97      0.97      3266\n","weighted avg       0.97      0.97      0.97      3266\n","\n","Accuracy at holdout: 0.9730557256582976\n","Precision at holdout: 0.9667673716012085\n","Recall at holdout: 0.9797917942437232\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"U_T86nzQSOLe","colab_type":"text"},"source":["**Observations**:\n","Although overall accuracy in holdout is lower than ensemble voting, the precision for winning (1) is higher than ensemble voting due to lower false negative.  While ensemble voting better predicts true positives, ensemble stacking predicts more false positives (ensemble voting holds the lowest false positives (41)). Ensemble staking ensembles preform better than most models except Logistic, Adaboost and Multi Layer Perceptron."]},{"cell_type":"markdown","metadata":{"id":"EO18LZA5SOLf","colab_type":"text"},"source":["#### Stacking with Multi Layer Perceptron as Meta-classifier"]},{"cell_type":"code","metadata":{"id":"ml_1sNDUSOLg","colab_type":"code","outputId":"42a535a9-2719-49d7-c332-32c71a3e0016","colab":{}},"source":["RANDOM_SEED = 23\n","# models used in this ensemble (which produces the best precision): \n","# logreg, random forest, adaboost, multilayer perceptron\n","\n","lr = mlp #mlp will be used as meta classifier\n","clf1 = logreg\n","clf2 = gcv  #random forest (grid search)\n","clf3 = ada_best #boosting Decision Tree\n","\n","sclf2 = StackingCVClassifier(classifiers=[clf1, clf2, clf3],\n","                            meta_classifier=lr,\n","                            random_state=RANDOM_SEED)\n","\n","print('3-fold cross validation:\\n')\n","\n","for clf, label in zip([clf1, clf2, clf3, sclf2], \n","                      ['Logistic',\n","                       'Random Forest',\n","                       'Boosting Decision Tree',\n","                       'Stacking Classifier']):\n","\n","    scores = cross_val_score(clf, scaledtrain_teamX, train_teamY, \n","                                              cv=3, scoring='accuracy')\n","    print(\"Accuracy at train: %0.3f (+/- %0.3f) [%s]\" \n","          % (scores.mean(), scores.std(), label))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["3-fold cross validation:\n","\n","Accuracy at train: 0.978 (+/- 0.001) [Logistic]\n","Accuracy at train: 0.973 (+/- 0.002) [Random Forest]\n","Accuracy at train: 0.974 (+/- 0.001) [Boosting Decision Tree]\n","Accuracy at train: 0.978 (+/- 0.001) [Stacking Classifier]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t6d0MJvJSOLk","colab_type":"code","outputId":"a9e743ab-ea35-417a-8e8b-94bf43759384","colab":{}},"source":["sclf2.fit(scaledtrain_teamX, train_teamY)\n","sclf2_accuracy = np.mean(train_teamY == sclf2.predict(scaledtrain_teamX))\n","print('accuracy at train:', sclf2_accuracy)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["accuracy at train: 0.9796587926509186\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V4GI0-RvSOLm","colab_type":"code","outputId":"fb4081b8-620e-4bb4-d3c8-31cc2a0c2c71","colab":{}},"source":["sclf2_y_pred = sclf2.predict(scaledtest_teamX)\n","\n","sclf2_result = pd.DataFrame(confusion_matrix(test_teamY, sclf2_y_pred))\n","print(\"Confusion Matrix:\")\n","print(sclf2_result)\n","sclf2_result1 = classification_report(test_teamY, sclf2_y_pred)\n","print(\"Classification Report:\",)\n","print (sclf2_result1)\n","sclf2_result2 = accuracy_score(test_teamY, sclf2_y_pred)\n","print(\"Accuracy at holdout:\", sclf2_result2)\n","sclf2_precision = precision_score(test_teamY, sclf2_y_pred)\n","print(\"Precision at holdout:\", sclf2_precision)\n","sclf2_recall = recall_score(test_teamY, sclf2_y_pred)\n","print(\"Recall at holdout:\", sclf2_recall)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Confusion Matrix:\n","      0     1\n","0  1593    40\n","1    41  1592\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.98      0.98      1633\n","           1       0.98      0.97      0.98      1633\n","\n","    accuracy                           0.98      3266\n","   macro avg       0.98      0.98      0.98      3266\n","weighted avg       0.98      0.98      0.98      3266\n","\n","Accuracy at holdout: 0.9751990202082057\n","Precision at holdout: 0.9754901960784313\n","Recall at holdout: 0.9748928352725046\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tjl50zBySOLq","colab_type":"text"},"source":["**Observations**: \n","Overall accuracy is higher when we have multi layer perceptron as meta classifier as compared to previous stacking (when logistic is the meta classifier) as logistic is a better base learner. \n","This Stacking Ensemble has the highest precision with the lowest false postives and highest false negatives. \n","However, false negatives is higher than other ensembles but that is not our main concern. So, this Stacking performs the best and stable when compared to accuracy in training. "]},{"cell_type":"markdown","metadata":{"id":"M_Z_74rISOLr","colab_type":"text"},"source":["### Summary of overall accuracy, precision and recall of all models"]},{"cell_type":"code","metadata":{"id":"D9S5zmFtSOLs","colab_type":"code","outputId":"6c275ccd-6d39-4098-f774-704760fc462a","colab":{}},"source":["# accuracy at train\n","\n","accuracy_train = pd.DataFrame.from_dict({'Logistic'    :logreg_train_accuracy, \n","                        'Naive Bayes'                  :NB_train_accuracy,\n","                        'KNN'                          :KNN_train_accuracy,\n","                        'Random Forest'                :RF_train_accuracy,\n","                        'Bagging KNN'                  :bKNN_train_accuracy,\n","                        'Bagging Decision Tree'        :bdtree_train_accuracy,\n","                        'Adaboost Classifer'           :ada_train_accuracy,\n","                        'Multi Layer Perceptron'       : mlp_score,\n","                        'EnsembleVoting'               :Voting_score,\n","                        'EnsembleStacking (logreg)'     :sclf_accuracy,\n","                        'EnsembleStacking (MLP)'       :sclf2_accuracy}, \n","                                  orient='index',columns=['Accuracy_train'])\n","accuracy_train = accuracy_train.sort_values(by='Accuracy_train', ascending=False)\n","accuracy_train"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Accuracy_train</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Random Forest</th>\n","      <td>0.987664</td>\n","    </tr>\n","    <tr>\n","      <th>EnsembleStacking (logreg)</th>\n","      <td>0.982283</td>\n","    </tr>\n","    <tr>\n","      <th>EnsembleVoting</th>\n","      <td>0.981496</td>\n","    </tr>\n","    <tr>\n","      <th>Multi Layer Perceptron</th>\n","      <td>0.980577</td>\n","    </tr>\n","    <tr>\n","      <th>EnsembleStacking (MLP)</th>\n","      <td>0.979659</td>\n","    </tr>\n","    <tr>\n","      <th>Logistic</th>\n","      <td>0.978740</td>\n","    </tr>\n","    <tr>\n","      <th>Bagging Decision Tree</th>\n","      <td>0.978084</td>\n","    </tr>\n","    <tr>\n","      <th>Bagging KNN</th>\n","      <td>0.977428</td>\n","    </tr>\n","    <tr>\n","      <th>Adaboost Classifer</th>\n","      <td>0.976640</td>\n","    </tr>\n","    <tr>\n","      <th>KNN</th>\n","      <td>0.974672</td>\n","    </tr>\n","    <tr>\n","      <th>Naive Bayes</th>\n","      <td>0.962073</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                           Accuracy_train\n","Random Forest                    0.987664\n","EnsembleStacking (logreg)        0.982283\n","EnsembleVoting                   0.981496\n","Multi Layer Perceptron           0.980577\n","EnsembleStacking (MLP)           0.979659\n","Logistic                         0.978740\n","Bagging Decision Tree            0.978084\n","Bagging KNN                      0.977428\n","Adaboost Classifer               0.976640\n","KNN                              0.974672\n","Naive Bayes                      0.962073"]},"metadata":{"tags":[]},"execution_count":107}]},{"cell_type":"code","metadata":{"id":"fTBOBIVrSOLu","colab_type":"code","outputId":"51c82f73-eb92-4f00-e563-7a6dca6c5102","colab":{}},"source":["# accuracy at holdout\n","\n","accuracy_test = pd.DataFrame.from_dict({'Logistic'    :logreg_result2, \n","                        'Naive Bayes'                 :NB_result2,\n","                        'KNN'                         :KNN_result2,\n","                        'Random Forest'               :rfc_result2,\n","                        'Bagging KNN'                 :bKNN_result2,\n","                        'Bagging Decision Tree'       :bdtree_result2,\n","                        'Adaboost Classifer'           :ada_result2,\n","                        'Multi Layer Perceptron'       :mlp_result2,\n","                        'Ensemble Voting'              :eclf_result2,\n","                        'EnsembleStacking (logreg)'     :sclf_result2,\n","                        'EnsembleStacking (MLP)'       :sclf2_result2}, \n","                                  orient='index',columns=['Accuracy_holdout'])\n","accuracy_test = accuracy_test.sort_values(by='Accuracy_holdout', ascending=False)\n","accuracy_test"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Accuracy_holdout</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Ensemble Voting</th>\n","      <td>0.975811</td>\n","    </tr>\n","    <tr>\n","      <th>EnsembleStacking (MLP)</th>\n","      <td>0.975199</td>\n","    </tr>\n","    <tr>\n","      <th>Logistic</th>\n","      <td>0.974587</td>\n","    </tr>\n","    <tr>\n","      <th>Adaboost Classifer</th>\n","      <td>0.973974</td>\n","    </tr>\n","    <tr>\n","      <th>Multi Layer Perceptron</th>\n","      <td>0.973668</td>\n","    </tr>\n","    <tr>\n","      <th>EnsembleStacking (logreg)</th>\n","      <td>0.973056</td>\n","    </tr>\n","    <tr>\n","      <th>Bagging Decision Tree</th>\n","      <td>0.972750</td>\n","    </tr>\n","    <tr>\n","      <th>Random Forest</th>\n","      <td>0.970912</td>\n","    </tr>\n","    <tr>\n","      <th>Bagging KNN</th>\n","      <td>0.969994</td>\n","    </tr>\n","    <tr>\n","      <th>KNN</th>\n","      <td>0.967238</td>\n","    </tr>\n","    <tr>\n","      <th>Naive Bayes</th>\n","      <td>0.961115</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                           Accuracy_holdout\n","Ensemble Voting                    0.975811\n","EnsembleStacking (MLP)             0.975199\n","Logistic                           0.974587\n","Adaboost Classifer                 0.973974\n","Multi Layer Perceptron             0.973668\n","EnsembleStacking (logreg)          0.973056\n","Bagging Decision Tree              0.972750\n","Random Forest                      0.970912\n","Bagging KNN                        0.969994\n","KNN                                0.967238\n","Naive Bayes                        0.961115"]},"metadata":{"tags":[]},"execution_count":106}]},{"cell_type":"markdown","metadata":{"id":"20SydfwjSOLw","colab_type":"text"},"source":["Comparing accuracy in train and holdout, it seems like Ensemble Staking (MLP as meta classifier) performs more stable than Ensemble Voting. Logistic is stable too but its accuracy is lower than Ensemble Staking (MLP). Random Forest and Ensemble Stacking (logistic) are overfitting in training. "]},{"cell_type":"code","metadata":{"id":"SmBownLISOLw","colab_type":"code","outputId":"7eae8da9-70f5-4a93-cfd5-327233fbd5df","colab":{}},"source":["# precision at holdout\n","\n","precision = pd.DataFrame.from_dict({'Logistic'          :logreg_precision, \n","                        'Naive Bayes'                   :NB_precision,\n","                        'KNN'                           :KNN_precision,\n","                        'Random Forest'                 :rfc_precision,\n","                        'Bagging KNN'                   :bKNN_precision,\n","                        'Bagging Decision Tree'         :bdtree_precision,\n","                        'Adaboost Classifer'            :ada_precision,\n","                        'Multi Layer Perceptron'        : mlp_precision,\n","                        'Ensemble Voting'               :eclf_precision,\n","                        'Ensemble Stacking (logreg)'    :sclf_precision,\n","                        'Ensemble Stacking (MLP)'       :sclf2_precision}, \n","                                  orient='index',columns=['Precision'])\n","precision = precision.sort_values(by='Precision', ascending=False)\n","precision"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Precision</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Ensemble Stacking (MLP)</th>\n","      <td>0.975490</td>\n","    </tr>\n","    <tr>\n","      <th>Ensemble Voting</th>\n","      <td>0.974939</td>\n","    </tr>\n","    <tr>\n","      <th>Logistic</th>\n","      <td>0.973716</td>\n","    </tr>\n","    <tr>\n","      <th>Multi Layer Perceptron</th>\n","      <td>0.970785</td>\n","    </tr>\n","    <tr>\n","      <th>Adaboost Classifer</th>\n","      <td>0.967956</td>\n","    </tr>\n","    <tr>\n","      <th>Ensemble Stacking (logreg)</th>\n","      <td>0.966767</td>\n","    </tr>\n","    <tr>\n","      <th>Random Forest</th>\n","      <td>0.966061</td>\n","    </tr>\n","    <tr>\n","      <th>KNN</th>\n","      <td>0.963548</td>\n","    </tr>\n","    <tr>\n","      <th>Bagging Decision Tree</th>\n","      <td>0.963385</td>\n","    </tr>\n","    <tr>\n","      <th>Bagging KNN</th>\n","      <td>0.963186</td>\n","    </tr>\n","    <tr>\n","      <th>Naive Bayes</th>\n","      <td>0.956364</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                            Precision\n","Ensemble Stacking (MLP)      0.975490\n","Ensemble Voting              0.974939\n","Logistic                     0.973716\n","Multi Layer Perceptron       0.970785\n","Adaboost Classifer           0.967956\n","Ensemble Stacking (logreg)   0.966767\n","Random Forest                0.966061\n","KNN                          0.963548\n","Bagging Decision Tree        0.963385\n","Bagging KNN                  0.963186\n","Naive Bayes                  0.956364"]},"metadata":{"tags":[]},"execution_count":108}]},{"cell_type":"code","metadata":{"id":"P4C_SQYISOLz","colab_type":"code","outputId":"20cd092d-63f1-4fde-cea8-c26cb1d792e0","colab":{}},"source":["# recall at holdout\n","\n","recall = pd.DataFrame.from_dict({'Logistic'         :logreg_recall, \n","                        'Naive Bayes'               :NB_recall,\n","                        'KNN'                       :KNN_recall,\n","                        'Random Forest'             :rfc_recall,\n","                        'Bagging KNN'               :bKNN_recall,\n","                        'Bagging Decision Tree'     :bdtree_recall,\n","                        'Adaboost Classifer'        :ada_recall,\n","                        'Multi Layer Perceptron'    : mlp_recall,\n","                        'Ensemble Voting'           :eclf_recall,\n","                        'Ensemble Stacking (logreg)':sclf_recall,\n","                        'Ensemble Stacking (MLP)'   :sclf2_recall}, \n","                                  orient='index',columns=['Recall'])\n","recall = recall.sort_values(by='Recall', ascending=False)\n","recall"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Bagging Decision Tree</th>\n","      <td>0.982854</td>\n","    </tr>\n","    <tr>\n","      <th>Adaboost Classifer</th>\n","      <td>0.980404</td>\n","    </tr>\n","    <tr>\n","      <th>Ensemble Stacking (logreg)</th>\n","      <td>0.979792</td>\n","    </tr>\n","    <tr>\n","      <th>Bagging KNN</th>\n","      <td>0.977342</td>\n","    </tr>\n","    <tr>\n","      <th>Multi Layer Perceptron</th>\n","      <td>0.976730</td>\n","    </tr>\n","    <tr>\n","      <th>Ensemble Voting</th>\n","      <td>0.976730</td>\n","    </tr>\n","    <tr>\n","      <th>Random Forest</th>\n","      <td>0.976118</td>\n","    </tr>\n","    <tr>\n","      <th>Logistic</th>\n","      <td>0.975505</td>\n","    </tr>\n","    <tr>\n","      <th>Ensemble Stacking (MLP)</th>\n","      <td>0.974893</td>\n","    </tr>\n","    <tr>\n","      <th>KNN</th>\n","      <td>0.971219</td>\n","    </tr>\n","    <tr>\n","      <th>Naive Bayes</th>\n","      <td>0.966320</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                              Recall\n","Bagging Decision Tree       0.982854\n","Adaboost Classifer          0.980404\n","Ensemble Stacking (logreg)  0.979792\n","Bagging KNN                 0.977342\n","Multi Layer Perceptron      0.976730\n","Ensemble Voting             0.976730\n","Random Forest               0.976118\n","Logistic                    0.975505\n","Ensemble Stacking (MLP)     0.974893\n","KNN                         0.971219\n","Naive Bayes                 0.966320"]},"metadata":{"tags":[]},"execution_count":109}]},{"cell_type":"markdown","metadata":{"id":"Niff1MCUSOL1","colab_type":"text"},"source":["## Selecting the best model"]},{"cell_type":"markdown","metadata":{"id":"UFsf_et1SOL2","colab_type":"text"},"source":["Overall, Stacking Ensemble (base learners: logistic model, random forest model, and adaboost model; meta classifier: multilayer perceptron model) performs the best, especially in precision (lowest false positives)"]},{"cell_type":"code","metadata":{"id":"cYLmJOJgSOL3","colab_type":"code","outputId":"cc9ed582-b62f-4618-b26e-b3bf25d1a80d","colab":{}},"source":["# generate its ROC curve\n","\n","sclf2_roc_auc = roc_auc_score(test_teamY, sclf2.predict(scaledtest_teamX))\n","fpr, tpr, thresholds = roc_curve(test_teamY,sclf2.predict_proba(scaledtest_teamX)[:,1])\n","plt.figure()\n","plt.plot(fpr, tpr, label='Stacking Ensemble (area = %0.3f)' % sclf2_roc_auc)\n","plt.plot([0, 1], [0, 1],'r--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver operating characteristic')\n","plt.legend(loc=\"lower right\")"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x264c7807fd0>"]},"metadata":{"tags":[]},"execution_count":112},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"JeX6waE7SOL5","colab_type":"text"},"source":["ROC curve highlights that Stacking Ensemble produces less false positives and higher true positives"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vD3KpTYJ0n8m"},"source":["## Save normalizing and models using pickle"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HB9GvWHg0n8n"},"source":["Models are saved to be used in calculator\n"]},{"cell_type":"markdown","metadata":{"id":"R5OHo7-xSOL7","colab_type":"text"},"source":["Dummy new data to test on pickle:"]},{"cell_type":"code","metadata":{"id":"B5pw2P6hSOL7","colab_type":"code","colab":{}},"source":["link = 'https://drive.google.com/open?id=17uwHLjIfDWV-DJqZSNVlAi65leF3VeSL'\n","fluff, id = link.split('=')\n","downloaded = drive.CreateFile({'id':id}) \n","downloaded.GetContentFile('Calculator_features.xlsx')  \n","calculator_features = pd.read_excel('Calculator_features.xlsx')\n","\n","calculator_features"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PozdMAP-0n8o"},"source":["### Pickle normalization process"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IQ6wiCyQ0n8p","colab":{}},"source":["# using the scale in training set\n","# Save scaler to file in the current working directory\n","# link = 'https://drive.google.com/open?id=1bwcZ4-YqhUlexAolQ0e9GxvKHc0HtSCg'\n","# fluff, id = link.split('=')\n","# downloaded = drive.CreateFile({'id':id}) \n","# downloaded.GetContentFile('scaler.pkl') \n","\n","scaler_filename = \"scaler.pkl\"\n","#with open(scaler_filename, 'wb') as scalerfile:\n","#    pickle.dump(scaler, scalerfile)\n","    \n","# Load from file\n","with open(scaler_filename, 'rb') as scalerfile:\n","    pickle_scaler = pickle.load(scalerfile)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HJ4r6ctw0n8q","outputId":"586bfd1e-e6f1-4f33-93e9-26e136eb49e0","scrolled":true,"colab":{}},"source":["scaled_calculatorfeatures = pickle_scaler.transform(calculator_features)\n","scaled_calculatorfeatures"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ -0.24534682,  -0.69661777,   0.99398137,  -0.30739642,\n","         -1.5532756 ,  -0.57916875,  -1.1175161 ,  -4.21004401,\n","        -22.67418681,   8.04854443]])"]},"metadata":{"tags":[]},"execution_count":120}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"N2PJ0lop0n8t"},"source":["### Pickle logistic regression and run prediction"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VXoECSg30n8t","colab":{}},"source":["# Save NBclassifier to file in the current working directory\n","logit_filename = \"Logistic.pkl\"\n","#with open(logit_filename, 'wb') as logitfile:\n","#    pickle.dump(logreg, logitfile)\n","    \n","# Load from file\n","with open(logit_filename, 'rb') as logitfile:\n","    pickle_logitmodel = pickle.load(logitfile)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lfzsUOYs0n8u","outputId":"93b2958e-e933-45c4-9bbc-cc34b610d8a7","scrolled":true,"colab":{}},"source":["# predict probability of target values\n","logit_Ypredictprob = pickle_logitmodel.predict_proba(scaled_calculatorfeatures)[:,1]\n","print('Probabilities of winning:', logit_Ypredictprob)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Probabilities of winning: [3.13179592e-06]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Gbag6Xor0n8w"},"source":["### Pickle Naive Bayes classifier and run prediction"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PhMUE6gb0n8w","colab":{}},"source":["# Save NBclassifier to file in the current working directory\n","NB_filename = \"NB_model.pkl\"\n","#with open(NB_filename, 'wb') as NBfile:\n","#    pickle.dump(NBclassifier, NBfile)\n","    \n","# Load from file\n","with open(NB_filename, 'rb') as NBfile:\n","    pickle_NBmodel = pickle.load(NBfile)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"n32oHjxE0n8x","outputId":"a37d8023-1489-422b-a678-d004f541baf6","colab":{}},"source":["# Calculate the accuracy score of NB and predict target values\n","NB_Ypredictprob = pickle_NBmodel.predict_proba(scaled_calculatorfeatures)[:,1]\n","print('Probabilities of winning:', NB_Ypredictprob)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Probabilities of winning: [1.06427743e-19]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"imyf0Cqr0n8z"},"source":["### Pickle Bagging KNN classifier and run prediction"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EZFqFRfe0n8z","colab":{}},"source":["# Save KNNclassifier to file in the current working directory\n","KNN_filename = \"KNN_model.pkl\"\n","#with open(KNN_filename, 'wb') as KNNfile:\n","#    pickle.dump (bagging2, KNNfile)\n","    \n","# Load from file\n","with open(KNN_filename, 'rb') as KNNfile:\n","    pickle_KNNmodel = pickle.load(KNNfile)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xVBHkhdL0n81","outputId":"a4679b25-e582-4a7b-a643-c4ce81d4c567","colab":{}},"source":["# Calculate the accuracy score of KNN and predict target values\n","KNN_Ypredictprob = pickle_KNNmodel.predict_proba(scaled_calculatorfeatures)[:,1]\n","print('Probabilities of winning:', KNN_Ypredictprob)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Probabilities of winning: [0.42777778]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"E1t-MHBI0n83"},"source":["### Pickle Random Forest classifier and run prediction"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"738Xsr7j0n84","colab":{}},"source":["# Save RFclassifier to file in the current working directory\n","RFC_filename = \"RFC_model.pkl\"\n","#with open(RFC_filename, 'wb') as RFCfile:\n","#     pickle.dump(gcv, RFCfile)\n","    \n","# Load from file\n","with open(RFC_filename, 'rb') as RFCfile:\n","    pickle_RFCmodel = pickle.load(RFCfile)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PV3klCGH0n85","outputId":"c0dc2651-16c8-48cd-efad-80e79c3314ed","colab":{}},"source":["# Calculate the accuracy score of Random Forest and predict target values\n","RFC_Ypredictprob = pickle_RFCmodel.predict_proba(scaled_calculatorfeatures)[:,1]\n","print('Probabilities of winning:', RFC_Ypredictprob)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Probabilities of winning: [0.01100292]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lgUBdlpuSOMW","colab_type":"text"},"source":["### Pickle bagging Decision Tree and run prediction"]},{"cell_type":"code","metadata":{"id":"lWc7YyQuSOMY","colab_type":"code","colab":{}},"source":["# Save bagging DT classifier to file in the current working directory\n","bdt_filename = \"bDecisionTree_model.pkl\"\n","#with open(bdt_filename, 'wb') as bdtfile:\n","#    pickle.dump(bagging3, bdtfile)\n","    \n","# Load from file\n","with open(bdt_filename, 'rb') as bdtfile:\n","    pickle_bdt = pickle.load(bdtfile)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pEbFfymrSOMa","colab_type":"code","outputId":"973f5e46-6d6f-4eac-eecd-6f43120e0025","colab":{}},"source":["# Calculate the accuracy score of bagging Decision Tree and predict target values\n","bdt_Ypredictprob = pickle_bdt.predict_proba(scaled_calculatorfeatures)[:,1]\n","print('Probabilities of winning:', bdt_Ypredictprob)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Probabilities of winning: [0.04038268]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NXRV6B9nSOMc","colab_type":"text"},"source":["### Pickle Adaboost model and run prediction"]},{"cell_type":"code","metadata":{"id":"LhJvN96_SOMc","colab_type":"code","colab":{}},"source":["# Save adaboost classifier to file in the current working directory\n","ada_filename = \"adaboosting_model.pkl\"\n","#with open(ada_filename, 'wb') as adafile:\n","#    pickle.dump(ada_best, adafile)\n","    \n","# Load from file\n","with open(ada_filename, 'rb') as adafile:\n","    pickle_ada = pickle.load(adafile)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6GUbTQ6CSOMg","colab_type":"code","outputId":"dcb30100-08b7-46ee-afc2-22224aaeb0d0","colab":{}},"source":["# Calculate the accuracy score of adaboost and predict target values\n","ada_Ypredictprob = pickle_ada.predict_proba(scaled_calculatorfeatures)[:,1]\n","print('Probabilities of winning:', ada_Ypredictprob)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Probabilities of winning: [0.44611855]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ikzr9yU8SOMj","colab_type":"text"},"source":["### Pickle Multi Layer Perceptron"]},{"cell_type":"code","metadata":{"id":"s2DeBE3aSOMj","colab_type":"code","colab":{}},"source":["# Save bagging DT classifier to file in the current working directory\n","mlp_filename = \"mlp_model.pkl\"\n","#with open(mlp_filename, 'wb') as mlpfile:\n","#    pickle.dump(mlp, mlpfile)\n","    \n","# Load from file\n","with open(mlp_filename, 'rb') as mlpfile:\n","    pickle_mlp = pickle.load(mlpfile)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F7E5d0m9SOMl","colab_type":"code","outputId":"b0c881b0-d237-4635-9de0-84cda62cd543","colab":{}},"source":["# Calculate the accuracy score of bagging Decision Tree and predict target values\n","mlp_Ypredictprob = pickle_mlp.predict_proba(scaled_calculatorfeatures)[:,1]\n","print('Probabilities of winning:', mlp_Ypredictprob)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Probabilities of winning: [1.13269882e-16]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4uIavl2O0n86"},"source":["### Pickle Ensemble Voting Classifier and run prediction"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zoNRgXQ_0n87","colab":{}},"source":["# Save ensemble voting classifier to file in the current working directory\n","eclf_filename = \"Ensemblevoting_model.pkl\"\n","#with open(eclf_filename, 'wb') as eclffile:\n","#    pickle.dump(eclf, eclffile)\n","    \n","# Load from file\n","with open(eclf_filename, 'rb') as eclffile:\n","    pickle_eclf = pickle.load(eclffile)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aRCCA2Pn0n88","outputId":"51f1e56f-850e-40ab-c69c-313c4aae53f0","colab":{}},"source":["# Calculate the accuracy score of Ensemble Voting and predict target values\n","eclf_Ypredictprob = pickle_eclf.predict_proba(scaled_calculatorfeatures)[:,1]\n","print('Probabilities of winning:', eclf_Ypredictprob)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Probabilities of winning: [0.11428115]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aHhan9quSOMq","colab_type":"text"},"source":["### Pickle Stacking Classifier (MLP)"]},{"cell_type":"code","metadata":{"id":"WfVPdtdNSOMq","colab_type":"code","colab":{}},"source":["# Save stacking classifier to file in the current working directory\n","sclf2_filename = \"Stacking_model.pkl\"\n","#with open(sclf2_filename, 'wb') as sclffile:\n","#    pickle.dump(sclf2, sclffile)\n","    \n","# Load from file\n","with open(sclf2_filename, 'rb') as sclffile:\n","    pickle_sclf2 = pickle.load(sclffile)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mERvcByvSOMu","colab_type":"code","outputId":"230b982b-2d3c-4ce4-b88a-ffbe8543760c","colab":{}},"source":["# Calculate the accuracy score of stacking and predict target values\n","sclf_Ypredictprob = pickle_sclf2.predict_proba(scaled_calculatorfeatures)[:,1]\n","print('Probabilities of winning:', sclf_Ypredictprob)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Probabilities of winning: [0.01536449]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"X8PXoTDB0n8-"},"source":["### Get the best model's probability "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pBbd1VOK0n8-","outputId":"12c8197a-8dd6-4281-f4b3-b1343de29ef9","colab":{}},"source":["bestmodel_prob = float(sclf_Ypredictprob)\n","print(\"Average probability of all models is:\", bestmodel_prob)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Average probability of all models is: 0.01536449179415549\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VWdzTWV_0n9B"},"source":["## End-product development (calculator)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Wlzd8dPk0n9C","colab":{}},"source":["from tkinter import *\n","import pandas as pd\n","import pickle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tflhuHB50n9E","colab":{}},"source":["class LOLcalculator:\n","\n","    def __init__(self):\n","        # create a window\n","        window = Tk()\n","        window.title(\"League of Legends Match Calculator\") #set title\n","        window.configure(background='black')\n","        window.geometry(\"1300x1200\")\n","\n","        # create time\n","        localtime  = time.asctime(time.localtime(time.time()))\n","        titlelabel = Label(window, font=(\"Helvetica\", 24), text=\"LOL MATCH PREDICTION\", \n","                          fg=\"silver\", bg='black').grid(row=0, column=1, sticky=W)\n","        timelabel  = Label(window, font=(\"Helvetica\", 12), text=localtime, \n","                          fg=\"silver\", bg='black').grid(row=0, column=3, sticky=W)\n","        \n","        # create the input boxes\n","        dlabel     = Label(window, height=3,width=35, font=(\"Helvetica\", 14), fg=\"white\",bg=\"blue\", \n","                           text = \"Total deaths (count)\").grid(row=1, column=1, sticky=W)\n","        kpmlabel   = Label(window, height=3,width=35, font=(\"Helvetica\", 14),fg=\"white\",bg=\"blue\",\n","                           text = \"Kill rate per minute (0 to 2)\").grid(row=2, column=1, sticky=W)\n","        ftlabel    = Label(window, height=3,width=35, font=(\"Helvetica\", 14),fg=\"white\",bg=\"blue\",\n","                           text = \"First tower destroyed (0 or 1)\").grid(row=3, column=1, sticky=W)\n","        towerlabel = Label(window, height=3,width=35, font=(\"Helvetica\", 14),fg=\"white\",bg=\"blue\",\n","                           text = \"Total tower kills (count)\").grid(row=4, column=1, sticky=W)\n","        baronlabel = Label(window, height=3,width=35, font=(\"Helvetica\", 14),fg=\"white\",bg=\"blue\",\n","                           text = \"Time baron killed (mins)\").grid(row=5, column=1, sticky=W)\n","        elemlabel  = Label(window, height=3,width=35, font=(\"Helvetica\", 14),fg=\"white\",bg=\"blue\",\n","                           text = \"Total elementals killed (count)\").grid(row=6, column=1, sticky=W)\n","        wcpmlabel  = Label(window, height=3,width=35, font=(\"Helvetica\", 14),fg=\"white\",bg=\"blue\",\n","                           text = \"Total wards cleared per min (0 to 5)\").grid(row=7, column=1, sticky=W)\n","        minionlabel= Label(window, height=3,width=35, font=(\"Helvetica\", 14), fg=\"white\",bg=\"blue\",\n","                           text = \"Total minions killed (team)\").grid(row=8, column=1, sticky=W)\n","        xpat10label= Label(window, height=3,width=35, font=(\"Helvetica\", 14),fg=\"white\",bg=\"blue\",\n","                           text = \"Xp gained at 10 minutes (team)\").grid(row=9, column=1, sticky=W)\n","        gold15label= Label(window, height=3,width=35, font=(\"Helvetica\", 14),fg=\"white\",bg=\"blue\",\n","                           text = \"Gold difference at 15 min (-ve/+ve)\").grid(row=10, column=1, sticky=W)\n","        problabel  = Label(window, height=3,width=35, font=(\"Helvetica\", 14),fg=\"white\",bg=\"maroon\",\n","                           text = \"Probability of team winning the match (>0.5)\").grid(row=11, column=1, sticky=W)\n","        \n","        # functions to take inputs\n","        self.d = DoubleVar()\n","        Scale(window, orient=HORIZONTAL, length=500, width=25, sliderlength=10,\n","             from_=0,to=50, tickinterval=5, variable=self.d).grid(row = 1, column = 2)\n","        \n","        self.kpm = DoubleVar()\n","        Scale(window, orient=HORIZONTAL, length=500, width=25, sliderlength=10,\n","             from_=0.00,to=2.00, tickinterval=0.50, digits=3, resolution=0.01,\n","              variable=self.kpm).grid(row = 2, column = 2)\n","        \n","        self.ft = DoubleVar()\n","        Scale(window, orient=HORIZONTAL, length=500, width=25, sliderlength=10,\n","             from_=0,to=1, tickinterval=1, variable=self.ft).grid(row = 3, column = 2)\n","        \n","        self.teamtowerkills = DoubleVar()\n","        Scale(window, orient=HORIZONTAL, length=500, width=25, sliderlength=10,\n","             from_=0,to=11, tickinterval=1, variable=self.teamtowerkills).grid(row = 4, column = 2)\n","        \n","        self.fbarontime = DoubleVar() \n","        Scale(window, orient=HORIZONTAL, length=500, width=25, sliderlength=10,\n","             from_=19.00,to=50.00, tickinterval=5.00, digits=3, resolution=0.01,\n","              variable=self.fbarontime).grid(row = 5, column = 2)\n","        \n","        self.elementals = DoubleVar()\n","        Scale(window, orient=HORIZONTAL, length=500, width=25, sliderlength=10,\n","             from_=0,to=6, tickinterval=1, variable=self.elementals).grid(row = 6, column = 2)\n","        \n","        self.wcpm = DoubleVar()\n","        Scale(window, orient=HORIZONTAL, length=500, width=25, sliderlength=10,\n","             from_=0.00,to=4.00, tickinterval=0.50, digits=3, resolution=0.01,\n","              variable=self.wcpm).grid(row = 7, column = 2)\n","        \n","        self.minionkills = DoubleVar()\n","        Scale(window, orient=HORIZONTAL, length=500, width=25, sliderlength=10,\n","             from_=300,to=3500.00, tickinterval=500, variable=self.minionkills).grid(row = 8, column = 2)\n","        \n","        self.xpat10 = DoubleVar()\n","        Scale(window, orient=HORIZONTAL, length=500, width=25, sliderlength=10,\n","             from_=10000,to=25000, tickinterval=5000, variable=self.xpat10).grid(row = 9, column = 2)\n","        \n","        self.gdiffat15 = DoubleVar()\n","        Scale(window, orient=HORIZONTAL, length=500, width=25, sliderlength=10,\n","             from_=-15000,to=15000, tickinterval=5000, variable=self.gdiffat15).grid(row = 10, column = 2)\n","    \n","        self.probability= StringVar()\n","        lblprobability  = Label(window, width=35, font=(\"Helvetica\", 14),\n","                                textvariable= self.probability).grid(row=11,column=2,sticky=E)\n","    \n","        # create the button to compute prob of winning\n","        computeProbWin = Button(window, width=35,font=(\"Helvetica\", 14), bg='silver',\n","                                text=\"Compute Probability of Win\", \n","                                command = self.computeProbWin).grid(row=12, column=2,sticky=E)\n","        \n","        # create average stats scale\n","        dmean    = Label(window, height=4,width=40, font=(\"Helvetica\", 11),fg=\"white\",bg=\"purple\",\n","                           text = \"Average no. of death per team: 16 (lose),8 (win)\").grid(row=1, column=3, sticky=W)\n","        kpmmean    = Label(window, height=4,width=40, font=(\"Helvetica\", 11),fg=\"white\",bg=\"purple\",\n","                           text = \"Average kill rate per minute: 0.21 (lose), 0.46 (win)\").grid(row=2, column=3, sticky=W)\n","        ttkmean    = Label(window, height=4,width=40, font=(\"Helvetica\", 11),fg=\"white\",bg=\"purple\",\n","                           text = \"Average team tower kills: 3 (lose), 10 (win)\").grid(row=4, column=3, sticky=W)\n","        baronmean  = Label(window, height=4,width=40, font=(\"Helvetica\", 11),fg=\"white\",bg=\"purple\",\n","                           text = \"Average time baron killed: 26.4min\").grid(row=5, column=3, sticky=W)\n","        elemean    = Label(window, height=4,width=40, font=(\"Helvetica\", 11),fg=\"white\",bg=\"purple\",\n","                           text = \"Average elementals killed: 1 (lose), 3 (win)\").grid(row=6, column=3, sticky=W)\n","        wcpmmean   = Label(window, height=4,width=40, font=(\"Helvetica\", 11),fg=\"white\",bg=\"purple\",\n","                           text = \"Average wards cleared per min: 1.4 (lose), 1.5 (win)\").grid(row=7, column=3, sticky=W)\n","        minionmean = Label(window, height=4,width=40, font=(\"Helvetica\", 11),fg=\"white\",bg=\"purple\",\n","                           text = \"Average minions killed: 964 (lose), 983 (win)\").grid(row=8, column=3, sticky=W)\n","        xpat10mean = Label(window, height=4,width=40, font=(\"Helvetica\", 11), fg=\"white\",bg=\"purple\",\n","                           text = \"Average Xp gained@10 min: 18.4k (lose), 18.7k (win)\").grid(row=9, column=3, sticky=W)\n","        gold15mean = Label(window, height=4,width=40, font=(\"Helvetica\", 11),fg=\"white\",bg=\"purple\",\n","                           text = \"Average gold diff@15 min (win team): 1,189.4\").grid(row=10, column=3, sticky=W)\n","\n","        # create event loop\n","        window.mainloop()\n","    \n","    def computeProbWin(self):\n","        # import libraries\n","        import pickle\n","        import numpy as np\n","        import pandas as pd\n","        from mlxtend.classifier import StackingCVClassifier\n","\n","        \n","        # put values into dataframe\n","        array = np.array([float(self.d.get()),float(self.kpm.get()),\n","                          float(self.ft.get()),\n","                         float(self.teamtowerkills.get()),float(self.fbarontime.get()),\n","                          float(self.elementals.get()),float(self.wcpm.get()),\n","                         float(self.minionkills.get()), float(self.xpat10.get()), \n","                          float(self.gdiffat15.get())]).reshape(1,10)\n","  \n","        # build DataFrame on array with columns specified \n","        features = pd.DataFrame(array, columns=['d', 'kpm','ft','teamtowerkills',\n","                                         'fbarontime','elementals','wcpm',\n","                                         'minionkills','xpat10','gdiffat15'])\n","        \n","        # use scaler of training set\n","        scaler_filename = \"scaler.pkl\"\n","        with open(scaler_filename, 'rb') as scalerfile:\n","            pickle_scaler = pickle.load(scalerfile)\n","        scaled_features = pickle_scaler.transform(features)\n","         \n","        # Load Stacking Ensemble classifier\n","        sclf2_filename = \"Stacking_model.pkl\"\n","        with open(sclf2_filename, 'rb') as sclffile:\n","            pickle_sclf2 = pickle.load(sclffile)\n","            \n","       \n","        # run prediction from Stacking Ensemble classifier\n","        sclf_Ypredictprob2 = pickle_sclf2.predict_proba(scaled_features)[:,1]\n"," \n","     \n","        self.probability.set(float(sclf_Ypredictprob2))\n","        \n","        #root= Tk() # create the widget"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"y6CDHaHO0n9G","outputId":"95ca4aa5-81f9-4061-cede-c1020c82c26b","colab":{}},"source":["# call class to run the program\n","LOLcalculator()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<__main__.LOLcalculator at 0x264be8ac278>"]},"metadata":{"tags":[]},"execution_count":151}]}]}